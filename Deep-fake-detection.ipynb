{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/agni-ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/agni-ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/agni-ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/agni-ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/agni-ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/agni-ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rarfile\n",
    "\n",
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN() \n",
    "\n",
    "def detect_face(img): \n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB) \n",
    "    final = [] \n",
    "    detected_faces_raw = detector.detect_faces(img)\n",
    "    \n",
    "    if detected_faces_raw==[]: \n",
    "        print('no faces found') \n",
    "        return [] \n",
    "    \n",
    "    for x in detected_faces_raw: \n",
    "        x,y,w,h=x['box'] \n",
    "        final.append([x,y,w,h]) \n",
    "        return final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img,x,y,w,h): \n",
    "    x-=40 \n",
    "    y-=40 \n",
    "    w+=40 \n",
    "    h+=40 \n",
    "    if x<0: \n",
    "        x=0 \n",
    "    if y<=0: \n",
    "        y=0 \n",
    "    return cv2.resize(img[y:y+h,x:x+w],(92,92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(file_name):\n",
    "    cap = cv2.VideoCapture(file_name)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    _step = frame_count // 25\n",
    "    _next = _step\n",
    "    count = 0 \n",
    "    frames = list()\n",
    "    \n",
    "    while count < 25:\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if ret:\n",
    "            frame_no = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            \n",
    "            if frame_no == _next:\n",
    "                bb = detect_face(frame)\n",
    "                if bb:\n",
    "                    x,y,w,h = bb[0]\n",
    "                    img = crop(frame, x,y,w,h)\n",
    "                    frames.append(np.array(img))\n",
    "                    _next = frame_no + _step\n",
    "                    count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = rarfile.RarFile(\"UCF101.rar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [f.filename for f in rf.infolist() if f.filename.endswith(\".avi\")]\n",
    "file_names = [fp.split(\"/\")[-1] for fp in file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(8)\n",
    "\n",
    "process = pool.map(get_frames, file_paths)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13320it [03:11, 69.54it/s]\n"
     ]
    }
   ],
   "source": [
    "for v_num, v in tqdm(enumerate(process)):\n",
    "    for i_num, i in enumerate(v):\n",
    "        img = Image.fromarray(i)\n",
    "        img.save(\"training_data/real/img_{}_{}.jpg\".format(v_num,i_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_file_list = glob.glob(\"training_data/real/*.jpg\")\n",
    "fake_file_list = glob.glob(\"training_data/fake/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list()\n",
    "labels = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in fake_file_list:\n",
    "    img = cv2.imread(item)\n",
    "    resized = cv2.resize(img, (92,92), interpolation = cv2.INTER_AREA)\n",
    "    data.append(resized)\n",
    "    labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_count = len(fake_file_list)\n",
    "\n",
    "real_sampling = random.choices(real_file_list, k=real_data_count)\n",
    "\n",
    "for item in real_sampling:\n",
    "    img = cv2.imread(item)\n",
    "    resized = cv2.resize(img, (92,92), interpolation = cv2.INTER_AREA)\n",
    "    data.append(resized)\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(np.array(data), np.array(labels), test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/agni-ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agni-ubuntu/anaconda3/lib/python3.7/site-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/agni-ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "73281/73281 [==============================] - 1169s 16ms/step - loss: 0.0390 - crossentropy: 0.0390 - accuracy: 0.9860\n",
      "Epoch 2/3\n",
      "73281/73281 [==============================] - 1176s 16ms/step - loss: 0.0169 - crossentropy: 0.0169 - accuracy: 0.9945\n",
      "Epoch 3/3\n",
      "73281/73281 [==============================] - 1174s 16ms/step - loss: 0.0136 - crossentropy: 0.0136 - accuracy: 0.9954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff0c9bfbcd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = Input(shape=(92, 92, 3))\n",
    "base_model = MobileNet(input_shape=(92, 92, 3), alpha=1, include_top=False, pooling='avg')\n",
    "\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    # When 0, the first layer i.e. the input layer should be trainable=False\n",
    "    if i > 88:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "        \n",
    "x = base_model(input)\n",
    "x = Dense(1, activation='sigmoid', name='final_output')(x)\n",
    "\n",
    "model = Model(input, x)\n",
    "\n",
    "model.compile(Adam(lr=0.001), loss='binary_crossentropy', metrics=['crossentropy', 'accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"vid_detect_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(np.array(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = [round(float(i)) for i in predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.07314011243928"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(new_pred, np.array(test_y))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_classifier(frame_predictions):\n",
    "    new_pred = [round(float(i)) for i in frame_predictions]\n",
    "    ones = zeros = 0\n",
    "    \n",
    "    for pred in new_pred:\n",
    "        if pred == 1:\n",
    "            ones += 1\n",
    "        else:\n",
    "            zeros += 1\n",
    "            \n",
    "    if ones >= zeros:\n",
    "        return 1\n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18321it [04:03, 75.27it/s]\n"
     ]
    }
   ],
   "source": [
    "for v_num, v in tqdm(enumerate(test_x)):\n",
    "    for i_num, i in enumerate(v):\n",
    "        img = Image.fromarray(i)\n",
    "        img.save(\"output/test_img/img_{}_{}.jpg\".format(v_num,i_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_list = glob.glob(\"output/test_img/*.jpg\")\n",
    "\n",
    "df = pd.DataFrame(list(zip(test_file_list, new_pred)), columns =['The_Name_of_Img', 'Is_This_Img_real?']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"output/output.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
